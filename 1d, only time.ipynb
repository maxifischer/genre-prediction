{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from helper_files import pick_batch\n",
    "\n",
    "def gaussian_noise_layer(input_layer, std):\n",
    "    noise = tf.random_normal(shape=tf.shape(input_layer), mean=0.0, stddev=std, dtype=tf.float32) \n",
    "    return input_layer + noise\n",
    "\n",
    "def early_stop(current, winner, win_step, step, sess):\n",
    "    saver = tf.train.Saver()\n",
    "    path = \"./saved_model/\"\n",
    "\n",
    "    if current > winner:\n",
    "        saver.save(sess, path, step) #save the model\n",
    "        win_step = step\n",
    "        return winner, win_step\n",
    "    else:\n",
    "        if (step - win_step) >3000: # if no new winner for 3000 steps \n",
    "            with tf.Session() as sess: # restore the parameters\n",
    "                saver.restore(sess, save_path)\n",
    "        return -1, win_step\n",
    "\n",
    "def conv1D_layer(inpt, filter_size, init_weights, init_bias):\n",
    "    conv1d= tf.layers.conv2d(inpt,\n",
    "                                  filters = filter_size,\n",
    "                                   kernel_size = [2, int(inpt.shape[2])],\n",
    "                                   strides=[1, int(inpt.shape[2])],\n",
    "                                   padding=\"same\",\n",
    "                                   activation =  tf.nn.relu,\n",
    "                                   kernel_initializer = init_weights,\n",
    "                                   bias_initializer = init_bias)\n",
    "\n",
    "    mp_conv1 = tf.layers.max_pooling2d(inputs = conv1d,\n",
    "                                      pool_size = [2,1],\n",
    "                                      strides = 2,\n",
    "                                      padding = \"SAME\")\n",
    "    \n",
    "    mp_conv1_shape = mp_conv1.shape # shape of the output of the first layer\n",
    "    mp_conv1= tf.reshape(mp_conv1,[-1,int(mp_conv1_shape[1]),int(mp_conv1_shape[3]), 1])\n",
    "    mp_conv1_do = tf.layers.dropout(mp_conv1, rate=0.3, training = True) # DROPOUT\n",
    "    print(mp_conv1_do)\n",
    "    return mp_conv1_do    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.InteractiveSession()\n",
    "np.random.seed(25)\n",
    "random.seed(25)\n",
    "\n",
    "\n",
    "\n",
    "data = np.load('./data.npy')\n",
    "\n",
    "x = data[0] # specto (nr_of_tracks, 647, 128)\n",
    "y = data[1] # label\n",
    "\n",
    "# create train/test set\n",
    "(x_train, x_val, y_train, y_val) = train_test_split(x, y, test_size=0.3)\n",
    "\n",
    "\n",
    "##### declare varibales\n",
    "input_shape = x_train.shape[1:3] #(647, 128)\n",
    "input_data = tf.placeholder(tf.float32,shape=[None,input_shape[0], input_shape[1]])\n",
    "input_layer = tf.reshape(input_data,[-1,input_shape[0],input_shape[1], 1]) #[batch_size, timesteps, frequencies, channels]\n",
    "#input_rhsp = gaussian_noise_layer(input_rshp, 0.1) # Add noise\n",
    "\n",
    "# define initilizers\n",
    "init_weights = tf.variance_scaling_initializer(scale = 2.0, mode= 'fan_in', distribution= 'uniform')\n",
    "init_bias= tf.constant_initializer(0.1)\n",
    "\n",
    "fltrs=[64,128,256,512,1024,2048,4096, 4096, 4096,4096] #65-70ish%\n",
    "#fltrs=[64,128,256,256,512,512,512,512,1024,1024, 1024, 2048,2048,2048,4096,4096] #65-70ish%\n",
    "len(fltrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer  1\n",
      "Tensor(\"dropout/dropout/mul:0\", shape=(?, 324, 64, 1), dtype=float32)\n",
      "\n",
      "layer  2\n",
      "Tensor(\"dropout_1/dropout/mul:0\", shape=(?, 162, 128, 1), dtype=float32)\n",
      "\n",
      "layer  3\n",
      "Tensor(\"dropout_2/dropout/mul:0\", shape=(?, 81, 256, 1), dtype=float32)\n",
      "\n",
      "layer  4\n",
      "Tensor(\"dropout_3/dropout/mul:0\", shape=(?, 41, 512, 1), dtype=float32)\n",
      "\n",
      "layer  5\n",
      "Tensor(\"dropout_4/dropout/mul:0\", shape=(?, 21, 1024, 1), dtype=float32)\n",
      "\n",
      "layer  6\n",
      "Tensor(\"dropout_5/dropout/mul:0\", shape=(?, 11, 2048, 1), dtype=float32)\n",
      "\n",
      "layer  7\n",
      "Tensor(\"dropout_6/dropout/mul:0\", shape=(?, 6, 4096, 1), dtype=float32)\n",
      "\n",
      "layer  8\n",
      "Tensor(\"dropout_7/dropout/mul:0\", shape=(?, 3, 4096, 1), dtype=float32)\n",
      "\n",
      "layer  9\n",
      "Tensor(\"dropout_8/dropout/mul:0\", shape=(?, 2, 4096, 1), dtype=float32)\n",
      "\n",
      "layer  10\n",
      "Tensor(\"dropout_9/dropout/mul:0\", shape=(?, 1, 4096, 1), dtype=float32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, fltr in enumerate(fltrs):\n",
    "    print(\"layer \",idx+1)\n",
    "    input_layer = conv1D_layer(input_layer, fltr, init_weights, init_bias)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape the output + Dropout\n",
    "fl_shape = input_layer.shape\n",
    "fl_flat = tf.reshape(input_layer, [-1, int(fl_shape[1])* int(fl_shape[2])* int(fl_shape[3])]) #reshape to batch of vectors\n",
    "do_fl_flat= tf.layers.dropout(fl_flat, rate=0.5, training = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################\n",
    "############################### OUTPUT LAYER ####\n",
    "############################################\n",
    "\n",
    "\n",
    "logit= tf.layers.dense( inputs= do_fl_flat,\n",
    "                             units = 10,\n",
    "                            use_bias = True,\n",
    "                            kernel_initializer = init_weights,\n",
    "                            bias_initializer = init_bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step: 0 Test accuracy:  0.11333334\n",
      "Step: 100 Test accuracy:  0.21666665\n",
      "Step: 200 Test accuracy:  0.30666664\n",
      "Step: 300 Test accuracy:  0.3033333\n",
      "Step: 400 Test accuracy:  0.3766667\n",
      "Step: 500 Test accuracy:  0.38666666\n",
      "Step: 600 Test accuracy:  0.43000004\n",
      "Step: 700 Test accuracy:  0.42333332\n",
      "Step: 800 Test accuracy:  0.39000002\n",
      "Step: 900 Test accuracy:  0.47333333\n",
      "Step: 1000 Test accuracy:  0.48666668\n",
      "Step: 1100 Test accuracy:  0.48666668\n",
      "Step: 1200 Test accuracy:  0.51\n",
      "Step: 1300 Test accuracy:  0.5033334\n",
      "Step: 1400 Test accuracy:  0.51666665\n",
      "Step: 1500 Test accuracy:  0.5566667\n",
      "Step: 1600 Test accuracy:  0.54999995\n",
      "Step: 1700 Test accuracy:  0.52\n",
      "Step: 1800 Test accuracy:  0.52666664\n",
      "Step: 1900 Test accuracy:  0.5833333\n",
      "Step: 2000 Test accuracy:  0.56666666\n",
      "Step: 2100 Test accuracy:  0.5466666\n",
      "Step: 2200 Test accuracy:  0.61999995\n",
      "Step: 2300 Test accuracy:  0.5766667\n",
      "Step: 2400 Test accuracy:  0.58666664\n",
      "Step: 2500 Test accuracy:  0.6233333\n",
      "Step: 2600 Test accuracy:  0.63000005\n",
      "Step: 2700 Test accuracy:  0.6\n",
      "Step: 2800 Test accuracy:  0.6033333\n",
      "Step: 2900 Test accuracy:  0.6033333\n",
      "Step: 3000 Test accuracy:  0.5966667\n",
      "Step: 3100 Test accuracy:  0.59\n",
      "Step: 3200 Test accuracy:  0.5833333\n",
      "Step: 3300 Test accuracy:  0.6133333\n",
      "Step: 3400 Test accuracy:  0.6266667\n",
      "Step: 3500 Test accuracy:  0.66\n",
      "Step: 3600 Test accuracy:  0.60666674\n",
      "Step: 3700 Test accuracy:  0.59999996\n",
      "Step: 3800 Test accuracy:  0.6366667\n",
      "Step: 3900 Test accuracy:  0.6433334\n",
      "Step: 4000 Test accuracy:  0.61666673\n",
      "Step: 4100 Test accuracy:  0.5966667\n",
      "Step: 4200 Test accuracy:  0.66333336\n",
      "Step: 4300 Test accuracy:  0.6133334\n",
      "Step: 4400 Test accuracy:  0.65333337\n",
      "Step: 4500 Test accuracy:  0.6666667\n",
      "Step: 4600 Test accuracy:  0.60999995\n",
      "Step: 4700 Test accuracy:  0.66\n",
      "Step: 4800 Test accuracy:  0.6466667\n",
      "Step: 4900 Test accuracy:  0.62\n",
      "Step: 5000 Test accuracy:  0.65000004\n",
      "Step: 5100 Test accuracy:  0.6233334\n",
      "Step: 5200 Test accuracy:  0.66\n",
      "Step: 5300 Test accuracy:  0.64000005\n",
      "Step: 5400 Test accuracy:  0.68000007\n",
      "Step: 5500 Test accuracy:  0.64000005\n",
      "Step: 5600 Test accuracy:  0.6333334\n",
      "Step: 5700 Test accuracy:  0.67666674\n",
      "Step: 5800 Test accuracy:  0.6566667\n",
      "Step: 5900 Test accuracy:  0.61666673\n",
      "Step: 6000 Test accuracy:  0.68\n",
      "Step: 6100 Test accuracy:  0.67333335\n",
      "Step: 6200 Test accuracy:  0.68\n",
      "Step: 6300 Test accuracy:  0.68\n",
      "Step: 6400 Test accuracy:  0.68\n",
      "Step: 6500 Test accuracy:  0.6433333\n",
      "Step: 6600 Test accuracy:  0.64000005\n",
      "Step: 6700 Test accuracy:  0.69000006\n",
      "Step: 6800 Test accuracy:  0.62999994\n",
      "Step: 6900 Test accuracy:  0.7166667\n",
      "Step: 7000 Test accuracy:  0.7033334\n",
      "Step: 7100 Test accuracy:  0.65333337\n",
      "Step: 7200 Test accuracy:  0.6433334\n",
      "Step: 7300 Test accuracy:  0.64000005\n",
      "Step: 7400 Test accuracy:  0.67333335\n",
      "Step: 7500 Test accuracy:  0.68\n",
      "Step: 7600 Test accuracy:  0.6566667\n",
      "Step: 7700 Test accuracy:  0.6666667\n",
      "Step: 7800 Test accuracy:  0.69\n",
      "Step: 7900 Test accuracy:  0.6766667\n",
      "Step: 8000 Test accuracy:  0.73333335\n",
      "Step: 8100 Test accuracy:  0.5733333\n",
      "Step: 8200 Test accuracy:  0.67333335\n",
      "Step: 8300 Test accuracy:  0.71\n",
      "Step: 8400 Test accuracy:  0.6366667\n",
      "Step: 8500 Test accuracy:  0.6933333\n",
      "Step: 8600 Test accuracy:  0.6666667\n",
      "Step: 8700 Test accuracy:  0.68\n",
      "Step: 8800 Test accuracy:  0.68666667\n",
      "Step: 8900 Test accuracy:  0.71666664\n",
      "Step: 9000 Test accuracy:  0.67\n",
      "Step: 9100 Test accuracy:  0.6366667\n",
      "Step: 9200 Test accuracy:  0.68666667\n",
      "Step: 9300 Test accuracy:  0.6666667\n",
      "Step: 9400 Test accuracy:  0.69\n",
      "Step: 9500 Test accuracy:  0.6433334\n",
      "Step: 9600 Test accuracy:  0.66333336\n",
      "Step: 9700 Test accuracy:  0.68666667\n",
      "Step: 9800 Test accuracy:  0.56666666\n",
      "Step: 9900 Test accuracy:  0.7166667\n",
      "Step: 10000 Test accuracy:  0.70000005\n",
      "Step: 10100 Test accuracy:  0.5466667\n",
      "Step: 10200 Test accuracy:  0.6133334\n",
      "Step: 10300 Test accuracy:  0.65333337\n",
      "Step: 10400 Test accuracy:  0.67333335\n",
      "Step: 10500 Test accuracy:  0.6866667\n",
      "Step: 10600 Test accuracy:  0.6766667\n",
      "Step: 10700 Test accuracy:  0.6366667\n",
      "Step: 10800 Test accuracy:  0.72\n",
      "Step: 10900 Test accuracy:  0.6666667\n"
     ]
    }
   ],
   "source": [
    "y_pred = tf.argmax(logit, axis=-1, output_type=tf.int32) # gives idx of max value in logit\n",
    "y_real = tf.placeholder(tf.int32, [None,len(y[0])]) # gold standard\n",
    "y_real_int = tf.argmax(y_real, axis=-1, output_type=tf.int32)\n",
    "\n",
    "# implement crossentropy with softmax\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_real, logits=logit)\n",
    "cross_entropy = tf.reduce_mean(cross_entropy)\n",
    "tf.summary.scalar(\"cost\", cross_entropy)\n",
    "\n",
    "\n",
    "#### Evaluation (do here for efficency) Kuan says it belongs here ####\n",
    "correct_prediction = tf.equal(y_pred, y_real_int)\n",
    "# cast transforms boolean to floats\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# Training Step\n",
    "train_step = tf.train.AdamOptimizer().minimize(cross_entropy)\n",
    "\n",
    "###########################################################\n",
    "# initilize variables (give them random values)\n",
    "tf.global_variables_initializer().run()\n",
    "### tensorboard\n",
    "loss_summary = tf.summary.scalar(\"cost\", cross_entropy)\n",
    "train_acc_summary = tf.summary.scalar(\"train_acc\", accuracy)\n",
    "train_summary = tf.summary.merge((loss_summary, train_acc_summary))\n",
    "test_summary = tf.summary.scalar(\"test_acc\", accuracy)\n",
    "writer = tf.summary.FileWriter(\"/cache/tensorboard-logdir/time_15layer\")\n",
    "writer.add_graph(sess.graph)\n",
    "############################################################\n",
    "\n",
    "\n",
    "\n",
    "########## TRAINING PARAMETERS & TRAINING\n",
    "sample_size = x_train.shape[0]\n",
    "test_size = x_val.shape[0]\n",
    "batch_size = 64\n",
    "steps = 30000\n",
    "test_step = 100\n",
    "\n",
    "\n",
    "winner = 0\n",
    "win_step = 0\n",
    "for step, idxs in zip(range(steps), pick_batch(sample_size, batch_size)):\n",
    "    _, stats = sess.run((train_step, train_summary), feed_dict={input_data: x_train[idxs], y_real: y_train[idxs]})\n",
    "    writer.add_summary(stats, step)\n",
    "    if not (step % test_step):\n",
    "        test_acc=[]\n",
    "        for x_t,y_t in zip(np.split(x_val,6), np.split(y_val,6)): #split test set in 6 parts\n",
    "            acc = sess.run((accuracy), feed_dict={input_data: x_t, y_real: y_t})\n",
    "            test_acc.append(acc)\n",
    "            \n",
    "        mean_test_acc= np.mean(test_acc)\n",
    "        print(\"Step:\", step, \"Test accuracy: \", mean_test_acc)\n",
    "        writer.add_summary(sess.run(test_summary, {accuracy: mean_test_acc}), step)\n",
    "        \n",
    "        # early stopping\n",
    "        winner, win_step = early_stop(mean_test_acc, winner, win_step, step, sess)\n",
    "        if winner == -1:\n",
    "            break\n",
    "# clear the writer buffer\n",
    "writer.flush()\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
